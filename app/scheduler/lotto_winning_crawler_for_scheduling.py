from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import Select
from selenium.common.exceptions import NoSuchElementException, TimeoutException
from sqlalchemy.orm import scoped_session, sessionmaker
from webdriver_manager.chrome import ChromeDriverManager
import logging
import time
from app.models import WinningInfo, engine, LottoStore

# ë¡œê·¸ ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s %(levelname)s: %(message)s',
    handlers=[
        logging.FileHandler("winning_data_crawler.log", encoding='utf-8'),  # íŒŒì¼ì— ë¡œê·¸ë¥¼ ê¸°ë¡
        logging.StreamHandler()  # ì½˜ì†”ì— ë¡œê·¸ë¥¼ ì¶œë ¥
    ]
)
logger = logging.getLogger(__name__)

# ì„¸ì…˜ ìƒì„±
session_factory = sessionmaker(bind=engine)
Session = scoped_session(session_factory)

# Chrome Driver ì„¤ì • í•¨ìˆ˜
def initialize_driver():
    chrome_options = Options()
    chrome_options.add_argument("--headless")  # Headless ëª¨ë“œ
    chrome_options.add_argument("--no-sandbox")  # ë¦¬ëˆ…ìŠ¤ì—ì„œ ì‹¤í–‰ ì‹œ í•„ìš”
    chrome_options.add_argument("--disable-dev-shm-usage")  # ë¦¬ëˆ…ìŠ¤ì—ì„œ ì‹¤í–‰ ì‹œ í•„ìš”
    chrome_options.add_argument("--disable-gpu")  # GPU ë¹„í™œì„±í™”
    chrome_options.add_argument("--window-size=1920x1080")  # í™”ë©´ ì‚¬ì´ì¦ˆ ì„¤ì •
    
    driver_path = "/usr/local/bin/chromedriver"  # í¬ë¡¬ ë“œë¼ì´ë²„ ê²½ë¡œ ì§ì ‘ ì§€ì •
    service = Service(driver_path)
    driver = webdriver.Chrome(service=service, options=chrome_options)
    
    return driver

def collect_all_winning_data():
    driver = initialize_driver()  # ë“œë¼ì´ë²„ ì´ˆê¸°í™” ìœ„ì¹˜ ì´ë™
    data = {"lotto_stores": []}  # ë°ì´í„° ì´ˆê¸°í™”


    try:
        # í¬ë¡¤ë§í•  í˜ì´ì§€ ì ‘ì†
        driver.get('https://dhlottery.co.kr/store.do?method=topStore&pageGubun=L645')
        
        # í˜ì´ì§€ ë¡œë“œ ëŒ€ê¸°
        WebDriverWait(driver, 20).until(
            EC.presence_of_element_located((By.ID, 'drwNo'))
        )
        time.sleep(2)  # ì¶”ê°€ ëŒ€ê¸°
        
        # íšŒì°¨ ì„ íƒ ì˜µì…˜ ì¶”ì¶œ
        drwNo_select = Select(driver.find_element(By.ID, 'drwNo'))
        drwNo_options = [option.get_attribute('value') for option in drwNo_select.options]

        # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê°€ì¥ ìµœê·¼ì— ì €ì¥ëœ íšŒì°¨ ë²ˆí˜¸ ê°€ì ¸ì˜¤ê¸°
        latest_drwNo = WinningInfo.get_latest_drwNo(Session)

        # í¬ë¡¤ë§í•  íšŒì°¨ ë²”ìœ„ ì„¤ì •
        if latest_drwNo:
            drwNo_options = [drwNo for drwNo in drwNo_options if int(drwNo) > latest_drwNo]
        else:
            pass

        # ìµœì‹  ë¡œë˜ ë‹¹ì²¨ íšŒì°¨ê°€ ì´ë¯¸ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ë˜ì–´ ìˆìœ¼ë©´ ì¶”ê°€ í¬ë¡¤ë§ì´ í•„ìš”í•˜ì§€ ì•ŠìŒ
        if not drwNo_options:
            logger.info("ğŸ“¢ ìµœì‹  ë¡œë˜ ë‹¹ì²¨ íšŒì°¨ê°€ ì´ë¯¸ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì¶”ê°€ í¬ë¡¤ë§ì´ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return

        for drwNo in drwNo_options:
            logger.info(f"ğŸ¯ [íšŒì°¨ {drwNo} í¬ë¡¤ë§ ì¤‘...]")
            data["lotto_stores"] = []  # ê° íšŒì°¨ë§ˆë‹¤ ì´ˆê¸°í™”

            # íšŒì°¨ ì„ íƒ
            drwNo_select = Select(driver.find_element(By.ID, 'drwNo'))

            # íšŒì°¨ ì„ íƒ í›„ ì¡°íšŒ ë²„íŠ¼ í´ë¦­
            drwNo_select.select_by_value(drwNo)
            driver.find_element(By.ID, 'searchBtn').click()
            time.sleep(1)

            # ì²« í˜ì´ì§€ì˜ 1ë“±, 2ë“± ë°°ì¶œì  í¬ë¡¤ë§
            crawl_table(driver, data, drwNo, "1", "//div[@class='group_content'][1]//table", True)
            crawl_table(driver, data, drwNo, "2", "//div[@class='group_content'][2]//table")

            # 2ë²ˆì§¸ í˜ì´ì§€ë¶€í„° ë í˜ì´ì§€ê¹Œì§€ ìˆœíšŒí•˜ë©´ì„œ 2ë“± íŒë§¤ì  í¬ë¡¤ë§ í•¨ìˆ˜
            crawl_second_tier_stores(driver, data, drwNo)

            # í¬ë¡¤ë§í•œ ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
            for store_data in data["lotto_stores"]:
                store_id = store_data["store_id"]

                logger.info(f"ğŸ“Œ ì‹ ê·œ ë‹¹ì²¨ì : {store_data['name']}, ì£¼ì†Œ: {store_data['address']}, ë“±ìˆ˜: {store_data['rank']}, íšŒì°¨: {store_data['drwNo']}, ì¹´í…Œê³ ë¦¬: {store_data.get('category')}")

                
                # LottoStores í…Œì´ë¸”ì—ì„œ store_id í™•ì¸
                lotto_store = Session.query(LottoStore).filter_by(id=store_id).first()
                
                if lotto_store:
                    winning_info = WinningInfo(
                        draw_no=store_data["drwNo"],
                        rank=store_data["rank"],
                        category=store_data.get("category"),
                        store_id=store_id
                    )
                    
                    Session.add(winning_info)
                else:
                    print(f"Skipping store_id {store_id} as it doesn't exist in LottoStores table.")

                Session.commit()

        # ë°ì´í„° ìˆ˜ì§‘ í›„ Materialized View ê°±ì‹ 
        refresh_materialized_view()
    except Exception as e:
        logger.error(f"âŒ ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    finally:
        driver.quit()  # ë“œë¼ì´ë²„ ì¢…ë£Œ
        Session.remove()

# í…Œì´ë¸” í¬ë¡¤ë§ í•¨ìˆ˜
def crawl_table(driver, data, drwNo, rank, xpath, include_category=False):
    try:

        # í…Œì´ë¸” ë¡œë”© ëŒ€ê¸°
        table = WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.XPATH, xpath))
        )

        # í…Œì´ë¸” ë°ì´í„° ì¶”ì¶œ
        rows = table.find_elements(By.XPATH, ".//tbody/tr")

        # í…Œì´ë¸” ë°ì´í„° ìˆœíšŒ
        for row in rows:
            columns = row.find_elements(By.XPATH, ".//td")
            if "ì¡°íšŒ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤." in row.text:
                logger.info(f"ğŸ” {rank}ë“± ë°°ì¶œì  ì¡°íšŒ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                continue
            name = columns[1].text
            category = columns[2].text if include_category else None
            address = columns[3].text if include_category else columns[2].text
            store_id = row.find_element(By.XPATH, ".//a[contains(@onclick, 'showMapPage')]").get_attribute("onclick")
            store_id = store_id.split("'")[1]
            store_data = {
                "drwNo": drwNo,
                "rank": rank,
                "name": name,
                "address": address,
                "store_id": store_id
            }
            if include_category:
                store_data["category"] = category
            data["lotto_stores"].append(store_data)
    except (NoSuchElementException, TimeoutException):
        logger.error(f"âŒ {rank}ë“± ë°°ì¶œì  í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ë¡œë”© ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ë§ˆì§€ë§‰ í˜ì´ì§€ ë²ˆí˜¸ ì¶”ì • í•¨ìˆ˜
def estimate_last_page_number(driver):
    try:
        page_links = driver.find_elements(By.XPATH, "//div[@class='paginate_common']//a[contains(@onclick, 'selfSubmit')]")
        if len(page_links) > 0:
            page_numbers = [int(link.text) for link in page_links if link.text.isdigit()]
            max_page_number = max(page_numbers)
            end_page_link = driver.find_elements(By.XPATH, "//div[@class='paginate_common']//a[contains(@class, 'go end')]")
            if end_page_link:
                end_page_number = int(end_page_link[0].get_attribute("onclick").split("(")[1].split(")")[0])
                max_page_number = max(max_page_number, end_page_number)
            return max_page_number
        else:
            return 1
    except NoSuchElementException:
        return 1

# 2ë²ˆì§¸ í˜ì´ì§€ë¶€í„° ë í˜ì´ì§€ê¹Œì§€ ìˆœíšŒí•˜ë©´ì„œ 2ë“± íŒë§¤ì  í¬ë¡¤ë§ í•¨ìˆ˜
def crawl_second_tier_stores(driver, data, drwNo):
    page_number = 2
    max_page_number = estimate_last_page_number(driver)
    # logger.info(f"ğŸ“ 2ë“± ë°°ì¶œì  í¬ë¡¤ë§í•  ì´ í˜ì´ì§€ ìˆ˜: {max_page_number}")
    while page_number <= max_page_number:
        try:
            page_link = driver.find_element(By.XPATH, f"//div[@class='paginate_common']//a[contains(@onclick, 'selfSubmit({page_number})')]")
            page_link.click()
            time.sleep(2)  # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
            crawl_table(driver, data, drwNo, "2", "//div[@class='group_content'][2]//table")
            page_number += 1
        except (NoSuchElementException, TimeoutException):
            logger.error(f"âŒ í˜ì´ì§€ {page_number}ê°€ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ë¡œë”© ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤.")
            break

# Materialized View ê°±ì‹  í•¨ìˆ˜ ì¶”ê°€
def refresh_materialized_view():
    try:
        with engine.connect() as connection:
            connection.execute("REFRESH MATERIALIZED VIEW lotto_store_ranking;")
            logger.info("âœ… REFRESH MATERIALIZED VIEW lotto_store_ranking ì‹¤í–‰ ì™„ë£Œ.")
    except Exception as e:
        logger.error(f"âŒ REFRESH MATERIALIZED VIEW ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

if __name__ == '__main__':
    collect_all_winning_data()